global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

storage:
  tsdb:
    # Configures how old an out-of-order/out-of-bounds sample can be w.r.t. the TSDB max time.
    # An out-of-order/out-of-bounds sample is ingested into the TSDB as long as the timestamp
    # of the sample is >= TSDB.MaxTime-out_of_order_time_window.
    #
    # When out_of_order_time_window is >0, the errors out-of-order and out-of-bounds are
    # combined into a single error called 'too-old'; a sample is either (a) ingestible
    # into the TSDB, i.e. it is an in-order sample or an out-of-order/out-of-bounds sample
    # that is within the out-of-order window, or (b) too-old, i.e. not in-order
    # and before the out-of-order window.
    # [ out_of_order_time_window: <duration> | default = 0s ]
    #
    # MAKE SURE THIS IS SET TO A BIG NUMBER!! If using the default you won't be able to backfill for more than 2 hours
    # old samples!!!!
    out_of_order_time_window: 1y

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"
    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.
    static_configs:
      - targets: ["localhost:9090"]

  # This is the app under test
  - job_name: myapp
    scrape_interval: 15s # Change this value to override global scrape interval
    static_configs:
      - targets:
          - host.docker.internal:2112 # target app running locally
